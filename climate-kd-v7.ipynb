{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import the necessary libraries"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\nimport string\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nfrom sklearn.metrics import f1_score\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom imblearn.under_sampling import (RandomUnderSampler, \n                                    NearMiss, \n                                    InstanceHardnessThreshold,\n                                    CondensedNearestNeighbour,\n                                    EditedNearestNeighbours,\n                                    RepeatedEditedNearestNeighbours,\n                                    AllKNN,\n                                    NeighbourhoodCleaningRule,\n                                    OneSidedSelection,\n                                    TomekLinks)\n","execution_count":19,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load in your data from kaggle.  \nBy working in a kaggle kernel, you can access the data directly from the competition, as well as make your submission without downloading your output file"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/climate-change-edsa2020-21/train.csv')\ntest = pd.read_csv('../input/climate-change-edsa2020-21/test.csv')","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"                                             message  tweetid\n0  Europe will now be looking to China to make su...   169760\n1  Combine this with the polling of staffers re c...    35326\n2  The scary, unimpeachable evidence that climate...   224985\n3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>message</th>\n      <th>tweetid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Europe will now be looking to China to make su...</td>\n      <td>169760</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Combine this with the polling of staffers re c...</td>\n      <td>35326</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The scary, unimpeachable evidence that climate...</td>\n      <td>224985</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n      <td>476263</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n      <td>872928</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"   sentiment                                            message  tweetid\n0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n1          1  It's not like we lack evidence of anthropogeni...   126103\n2          2  RT @RawStory: Researchers say we have three ye...   698562\n3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>message</th>\n      <th>tweetid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n      <td>625221</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>It's not like we lack evidence of anthropogeni...</td>\n      <td>126103</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>RT @RawStory: Researchers say we have three ye...</td>\n      <td>698562</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n      <td>573736</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n      <td>466954</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sentiment.value_counts()","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":" 1    8530\n 2    3640\n 0    2353\n-1    1296\nName: sentiment, dtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Splitting out the X variable from the target"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['sentiment']\nX = train['message']","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"0        PolySciMajor EPA chief doesn't think carbon di...\n1        It's not like we lack evidence of anthropogeni...\n2        RT @RawStory: Researchers say we have three ye...\n3        #TodayinMaker# WIRED : 2016 was a pivotal year...\n4        RT @SoyNovioDeTodas: It's 2016, and a racist, ...\n                               ...                        \n15814    RT @ezlusztig: They took down the material on ...\n15815    RT @washingtonpost: How climate change could b...\n15816    notiven: RT: nytimesworld :What does Trump act...\n15817    RT @sara8smiles: Hey liberals the climate chan...\n15818    RT @Chet_Cannon: .@kurteichenwald's 'climate c...\nName: message, Length: 15819, dtype: object"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Resampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.utils import resample\n#positive = train[train['sentiment'] == 1]\n#negative = train[train['sentiment'] == -1]\n#neutral = train[train['sentiment'] == 0] \n#other = train[train['sentiment'] == 2]\n\n#negative_upsampled = resample(positive, replace=True, n_samples=len(other), random_state=27)\n#neutral_upsampled = resample(neutral, replace=True, n_samples=len(other), random_state=27)\n#unk_upsampled = resample(unk, replace=True, n_samples=len(other), random_state=27)\n\n#U_train = pd.concat([positive, negative_upsampled, neutral_upsampled, unk_upsampled])","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#U_train.info()","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import PorterStemmer\n# init stemmer\nporter_stemmer=PorterStemmer()\ndef prssor(text):\n    text=text.lower() \n    text=re.sub(\"\\\\W\",\" \",text) # remove special chars\n    text=re.sub(\"\\\\s+(in|the|all|for|and|on)\\\\s+\",\" _connector_ \",text) # normalize certain words\n    # stem words\n    words=re.split(\"\\\\s+\",text)\n    stemmed_words=[porter_stemmer.stem(word=word) for word in words]\n    return ' '.join(stemmed_words)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from nltk.tokenize import TweetTokenizer\n#tknzr = TweetTokenizer()\n#trr = train\n#tknzr.tokenize(s0)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tknzr(text):\n    # create a space between special characters \n    text=re.sub(\"(\\\\W)\",\" \\\\1 \",text)\n    # split based on whitespace\n    return re.split(\"\\\\s+\",text)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y = U_train['sentiment']\n#X = U_train['message']","execution_count":31,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Turning text into something your model can read"},{"metadata":{"trusted":true},"cell_type":"code","source":"#vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=2, stop_words=\"english\")\n#X_vectorized = vectorizer.fit_transform(X)","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(ngram_range=(1,2),tokenizer=tknzr, min_df=2,max_df=0.80,analyzer='word',smooth_idf=False, preprocessor=prssor,stop_words=\"english\")\nX_vectorized = vectorizer.fit_transform(X)","execution_count":33,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n  'stop_words.' % sorted(inconsistent))\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_vectorized","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"<15819x25747 sparse matrix of type '<class 'numpy.float64'>'\n\twith 364098 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the training data into a training and validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train,X_val,y_train,y_val = train_test_split(X_vectorized,y,test_size=.3,shuffle=True, stratify=y, random_state=11)","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_val,y_train,y_val = train_test_split(X_vectorized,y,test_size=0.30,shuffle=True, random_state=25)","execution_count":36,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the model and evaluating using the validation set "},{"metadata":{"trusted":true},"cell_type":"code","source":"sampler =AllKNN(allow_minority=True)\nenn_xtrain_tfidf, enn_train_y = sampler.fit_sample(X_train, y_train)","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rfc = RandomForestClassifier()\n#rfc.fit(X_train, y_train)\n#rfc_pred = rfc.predict(X_val)","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lsvc = LinearSVC()\nlsvc.fit(X_train, y_train)\nlsvc_pred = lsvc.predict(X_val)","execution_count":39,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking the performance of our model on the validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(y_val, lsvc_pred, average=\"macro\")","execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"0.6488151457000704"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nprint(metrics.classification_report(y_val, lsvc_pred))","execution_count":41,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n          -1       0.71      0.43      0.53       386\n           0       0.59      0.43      0.49       713\n           1       0.76      0.86      0.81      2572\n           2       0.76      0.76      0.76      1075\n\n    accuracy                           0.74      4746\n   macro avg       0.70      0.62      0.65      4746\nweighted avg       0.73      0.74      0.73      4746\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Getting our test set ready "},{"metadata":{"trusted":true},"cell_type":"code","source":"testx = test['message']\ntest_vect = vectorizer.transform(testx)","execution_count":42,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making predictions on the test set and adding a sentiment column to our original test df"},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_pred = rfc.predict(test_vect)","execution_count":43,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'rfc' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-17d8203b3b35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_vect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'rfc' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lsvc.predict(test_vect)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['sentiment'] = y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating an output csv for submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['tweetid','sentiment']].to_csv('KD_SUB_10.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}