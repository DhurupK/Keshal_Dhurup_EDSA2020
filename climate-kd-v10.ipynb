{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import the necessary libraries"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\nimport string\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nfrom sklearn.metrics import f1_score\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom imblearn.under_sampling import (RandomUnderSampler, \n                                    NearMiss, \n                                    InstanceHardnessThreshold,\n                                    CondensedNearestNeighbour,\n                                    EditedNearestNeighbours,\n                                    RepeatedEditedNearestNeighbours,\n                                    AllKNN,\n                                    NeighbourhoodCleaningRule,\n                                    OneSidedSelection,\n                                    TomekLinks)\nfrom bs4 import BeautifulSoup             \nimport re\nfrom nltk.stem import PorterStemmer\nporter_stemmer=PorterStemmer()","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load in your data from kaggle.  \nBy working in a kaggle kernel, you can access the data directly from the competition, as well as make your submission without downloading your output file"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/climate-change-edsa2020-21/train.csv')\ntest = pd.read_csv('../input/climate-change-edsa2020-21/test.csv')","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"                                             message  tweetid\n0  Europe will now be looking to China to make su...   169760\n1  Combine this with the polling of staffers re c...    35326\n2  The scary, unimpeachable evidence that climate...   224985\n3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>message</th>\n      <th>tweetid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Europe will now be looking to China to make su...</td>\n      <td>169760</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Combine this with the polling of staffers re c...</td>\n      <td>35326</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The scary, unimpeachable evidence that climate...</td>\n      <td>224985</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n      <td>476263</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n      <td>872928</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"   sentiment                                            message  tweetid\n0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n1          1  It's not like we lack evidence of anthropogeni...   126103\n2          2  RT @RawStory: Researchers say we have three ye...   698562\n3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>message</th>\n      <th>tweetid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n      <td>625221</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>It's not like we lack evidence of anthropogeni...</td>\n      <td>126103</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>RT @RawStory: Researchers say we have three ye...</td>\n      <td>698562</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n      <td>573736</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n      <td>466954</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sentiment.value_counts()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":" 1    8530\n 2    3640\n 0    2353\n-1    1296\nName: sentiment, dtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Splitting out the X variable from the target"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['sentiment']\nX = train['message']","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"0        PolySciMajor EPA chief doesn't think carbon di...\n1        It's not like we lack evidence of anthropogeni...\n2        RT @RawStory: Researchers say we have three ye...\n3        #TodayinMaker# WIRED : 2016 was a pivotal year...\n4        RT @SoyNovioDeTodas: It's 2016, and a racist, ...\n                               ...                        \n15814    RT @ezlusztig: They took down the material on ...\n15815    RT @washingtonpost: How climate change could b...\n15816    notiven: RT: nytimesworld :What does Trump act...\n15817    RT @sara8smiles: Hey liberals the climate chan...\n15818    RT @Chet_Cannon: .@kurteichenwald's 'climate c...\nName: message, Length: 15819, dtype: object"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Resampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.utils import resample\n#positive = train[train['sentiment'] == 1]\n#negative = train[train['sentiment'] == -1]\n#neutral = train[train['sentiment'] == 0] \n#other = train[train['sentiment'] == 2]\n\n#negative_upsampled = resample(positive, replace=True, n_samples=len(other), random_state=27)\n#neutral_upsampled = resample(neutral, replace=True, n_samples=len(other), random_state=27)\n#unk_upsampled = resample(unk, replace=True, n_samples=len(other), random_state=27)\n\n#U_train = pd.concat([positive, negative_upsampled, neutral_upsampled, unk_upsampled])","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#U_train.info()","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tweettoword(tweet): \n    t1 = BeautifulSoup(tweet).get_text()  # Remove HTML   \n    letters = re.sub(\"[^a-zA-Z]\", \" \", t1) # get letters\n    sp_char= re.sub(\"\\\\W\",\" \",t1) # remove special chars\n    words = letters.lower().split()  # convert to lowercase and split into words                                        \n    #stops = stopwords.words(\"english\")                \n    #useful_words = [w for w in words if not w in stops]\n    #useful_words1 = \" \".join(useful_words) #Join to useful words\n    stemmed_words=[porter_stemmer.stem(word=word) for word in words] #\n\n    return \" \".join(stemmed_words) #Join to useful words","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from nltk.tokenize import TweetTokenizer\n#tknzr = TweetTokenizer()\n#trr = train\n#tknzr.tokenize(s0)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tknzr(text):\n    # create a space between special characters \n    text=re.sub(\"(\\\\W)\",\" \\\\1 \",text)\n    # split based on whitespace\n    return re.split(\"\\\\s+\",text)","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y = U_train['sentiment']\n#X = U_train['message']","execution_count":31,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Turning text into something your model can read"},{"metadata":{"trusted":true},"cell_type":"code","source":"#vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=2, stop_words=\"english\")\n#X_vectorized = vectorizer.fit_transform(X)","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(ngram_range=(1,2),\n                             tokenizer=tknzr, \n                             min_df=2,\n                             max_df=0.80,\n                             analyzer='word',\n                             smooth_idf=False, \n                             preprocessor=tweettoword,\n                             token_pattern=r'\\w{1,}', \n                             max_features=100000,\n                             stop_words=\"english\")\nX_vectorized = vectorizer.fit_transform(X)","execution_count":63,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n  'stop_words.' % sorted(inconsistent))\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_vectorized","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"<15819x24282 sparse matrix of type '<class 'numpy.float64'>'\n\twith 266216 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the training data into a training and validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train,X_val,y_train,y_val = train_test_split(X_vectorized,y,test_size=.3,shuffle=True, stratify=y, random_state=11)","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_val,y_train,y_val = train_test_split(X_vectorized,\n                                               y,\n                                               test_size=0.20,\n                                               shuffle=True, \n                                               random_state=32)","execution_count":97,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the model and evaluating using the validation set "},{"metadata":{"trusted":true},"cell_type":"code","source":"sampler =AllKNN(allow_minority=True)\nenn_xtrain_tfidf, enn_train_y = sampler.fit_sample(X_train, y_train)","execution_count":93,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rfc = RandomForestClassifier()\n#rfc.fit(X_train, y_train)\n#rfc_pred = rfc.predict(X_val)","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lsvc = LinearSVC()\nlsvc.fit(X_train, y_train)\nlsvc_pred = lsvc.predict(X_val)","execution_count":98,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking the performance of our model on the validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(y_val, lsvc_pred, average=\"macro\")","execution_count":99,"outputs":[{"output_type":"execute_result","execution_count":99,"data":{"text/plain":"0.6481932313304015"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nprint(metrics.classification_report(y_val, lsvc_pred))","execution_count":91,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n          -1       0.70      0.41      0.52       383\n           0       0.57      0.41      0.48       674\n           1       0.77      0.87      0.81      2614\n           2       0.75      0.75      0.75      1075\n\n    accuracy                           0.74      4746\n   macro avg       0.70      0.61      0.64      4746\nweighted avg       0.73      0.74      0.73      4746\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Getting our test set ready "},{"metadata":{"trusted":true},"cell_type":"code","source":"testx = test['message']\ntest_vect = vectorizer.transform(testx)","execution_count":82,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making predictions on the test set and adding a sentiment column to our original test df"},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_pred = rfc.predict(test_vect)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lsvc.predict(test_vect)","execution_count":83,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['sentiment'] = y_pred","execution_count":84,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":85,"outputs":[{"output_type":"execute_result","execution_count":85,"data":{"text/plain":"                                             message  tweetid  sentiment\n0  Europe will now be looking to China to make su...   169760          1\n1  Combine this with the polling of staffers re c...    35326          0\n2  The scary, unimpeachable evidence that climate...   224985          1\n3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263          1\n4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928          0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>message</th>\n      <th>tweetid</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Europe will now be looking to China to make su...</td>\n      <td>169760</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Combine this with the polling of staffers re c...</td>\n      <td>35326</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The scary, unimpeachable evidence that climate...</td>\n      <td>224985</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n      <td>476263</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n      <td>872928</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Creating an output csv for submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['tweetid','sentiment']].to_csv('KD_SUB_14.csv', index=False)","execution_count":86,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}